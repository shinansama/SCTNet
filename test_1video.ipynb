{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b7df4ea-0e7e-4c6d-a51a-dfe295aa2a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 15:56:10,559 - mmcv - INFO - initialize SCTNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'pretrain/SCT-B_Pretrain.pth'}\n",
      "2024-11-29 15:56:10,560 - mmcv - INFO - load model from: pretrain/SCT-B_Pretrain.pth\n",
      "2024-11-29 15:56:10,561 - mmcv - INFO - load checkpoint from local path: pretrain/SCT-B_Pretrain.pth\n",
      "2024-11-29 15:56:11,427 - mmcv - INFO - initialize VitGuidanceHead with init_cfg {'type': 'Pretrained', 'checkpoint': 'pretrain/Teacher_SegFormer_B3_ADE.pth'}\n",
      "2024-11-29 15:56:11,432 - mmcv - INFO - load model from: pretrain/Teacher_SegFormer_B3_ADE.pth\n",
      "2024-11-29 15:56:11,433 - mmcv - INFO - load checkpoint from local path: pretrain/Teacher_SegFormer_B3_ADE.pth\n",
      "2024-11-29 15:56:12,039 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for teacher_head.conv_seg.weight: copying a param with shape torch.Size([150, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([37, 256, 1, 1]).\n",
      "size mismatch for teacher_head.conv_seg.bias: copying a param with shape torch.Size([150]) from checkpoint, the shape in current model is torch.Size([37]).\n",
      "missing keys in source state_dict: feature_transforms.weight, feature_transforms.bias, convstage4.weight, convstage4.bias, convstage3.weight, convstage3.bias\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: work_dirs/sctnet-b_8x4_160k_pets/iter_108000.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video: 100%|██████████| 358/358 [01:14<00:00,  4.78frame/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final average FPS: 4.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from mmseg.apis import init_segmentor, inference_segmentor\n",
    "\n",
    "config_file = r\"configs/sctnet/pets/sctnet-b_8x4_160k_pets.py\"\n",
    "checkpoint_file = r\"work_dirs/sctnet-b_8x4_160k_pets/latest.pth\"\n",
    "\n",
    "# 初始化模型\n",
    "model = init_segmentor(config_file, checkpoint_file, device='cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 输入视频文件路径，替换为你实际的视频文件路径\n",
    "input_video_path = 'demo/dog_stare.mp4'\n",
    "# 输出视频文件路径，可自行指定输出的文件名及路径\n",
    "output_video_path = 'output.mp4'\n",
    "\n",
    "# 打开输入视频文件\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# 获取视频的一些基本属性\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)  # 获取帧率\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # 获取视频宽度\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # 获取视频高度\n",
    "\n",
    "# 创建VideoWriter对象，用于输出新视频\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # 视频编解码器，这里使用mp4v，可根据需求调整\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "\n",
    "# 获取视频总帧数\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# 使用tqdm创建进度条，设置总迭代次数为视频总帧数\n",
    "with tqdm(total=total_frames, desc=\"Processing video\", unit=\"frame\") as pbar:\n",
    "    start_time = time.time()  # 记录视频处理开始时间\n",
    "    frame_count = 0  # 用于记录已处理的帧数\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            with torch.no_grad():\n",
    "                result = inference_segmentor(model, frame)\n",
    "                # 将处理后的帧写入新视频文件\n",
    "                out.write(model.show_result(frame, result))\n",
    "            frame_count += 1\n",
    "            # 更新进度条\n",
    "            pbar.update(1)\n",
    "        else:\n",
    "            break\n",
    "    end_time = time.time()  # 记录视频处理结束时间\n",
    "    total_elapsed_time = end_time - start_time\n",
    "    final_fps = frame_count / total_elapsed_time\n",
    "    print(f\"Final average FPS: {final_fps:.2f}\")\n",
    "\n",
    "# 释放资源\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a65602-af40-497b-b0e9-811496a64cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCTNet",
   "language": "python",
   "name": "sctnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
